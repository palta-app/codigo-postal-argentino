{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías.\n",
    "import csv\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que realiza consultas a la [web](https://codigo-postal.co/argentina/) para extraer las variables __provincia__ y __localidad__.\n",
    "El código proporcionado en la función llamada __extraer_localities_base()__ se encarga de extraer datos de localidades y provincias del sitio [web](https://codigo-postal.co/argentina/)  y guardarlos en un archivo CSV(_localities_new.csv_). A continuación, se comentan las líneas de código para comprender su significado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_localities_base():\n",
    "    \n",
    "    \"\"\"En estas líneas, se abre un archivo JSON llamado 'statesCode.json' y se carga su contenido en la variable provincias_list.\n",
    "    El archivo conteniene nombres de provincias.\"\"\"\n",
    "    with open('data/statesCode.json', 'r') as archivo:\n",
    "        provincias_list = list(dict(json.load(archivo)).keys())\n",
    "\n",
    "    \"\"\"Aquí se crean listas vacías llamadas localidades y provincias, y se inicializa una sesión de solicitud HTTP usando requests.Session().\n",
    "    Luego, se envía una solicitud GET a la URL 'https://codigo-postal.co/argentina/' y se guarda la respuesta en response1.\"\"\"\n",
    "    localidades = []\n",
    "    provincias = []\n",
    "    session = requests.Session()\n",
    "    response1 = session.get('https://codigo-postal.co/argentina/')\n",
    "\n",
    "    \"\"\"En este bucle for, se itera sobre cada provincia en provincias_list.\n",
    "    Se realiza una manipulación de cadenas en la variable pro para formatear la provincia en un formato adecuado para la URL.\n",
    "    Luego, se envía una solicitud GET a una URL específica para cada provincia y se guarda la respuesta en response2.\n",
    "    Si el código de estado de la respuesta es 200 (indicando una respuesta exitosa),\n",
    "    se guarda el contenido de la respuesta en content y se crea un objeto BeautifulSoup llamado soup para analizar el contenido HTML.\"\"\"\n",
    "    for p in provincias_list:\n",
    "        \n",
    "        pro = p.lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "        response2 = session.get(f'https://codigo-postal.co/argentina/{pro}')\n",
    "        if response2.status_code == 200:\n",
    "            content = response2.content\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "    \n",
    "        \"\"\"En estas líneas, se busca en el contenido HTML de la página ciertos elementos para obtener una lista de localidades.\n",
    "        Se utiliza soup.find() para encontrar un elemento con la clase \"container content_container\", luego se busca un elemento \"ul\"\n",
    "        y finalmente se encuentran todos los elementos \"li\" dentro de él. Se extrae el texto de los elementos \"a\" dentro de cada \"li\"\n",
    "        y se guarda en la lista localidad. Luego, se extiende la lista localidades con los elementos de localidad.\n",
    "        Además, se crea una lista de provincias llamada provincia donde cada elemento es el nombre de la provincia actual (p)\n",
    "        repetido tantas veces como localidades haya en la lista localidad.\n",
    "        Finalmente, se extiende la lista provincias con los elementos de provincia.\"\"\"\n",
    "        lista = soup.find(class_=\"container content_container\").find(\"ul\").find_all(\"li\")\n",
    "        localidad = [i.find(\"a\").get_text() for i in lista]\n",
    "        localidades.extend(localidad)  \n",
    "        provincia = [p] * len(localidad)\n",
    "        provincias.extend(provincia)\n",
    "\n",
    "    \"\"\"En estas líneas, se abre un nuevo archivo CSV llamado 'localities_new.csv' en modo de escritura. Se definen los nombres de campo ('provincia' y 'localidad')\n",
    "    y se crea un escritor de CSV (csv.DictWriter) usando el archivo y los nombres de campo. Luego, se itera sobre la lista combinada de provincias\n",
    "    y localidades utilizando zip() para obtener pares de valores correspondientes.\n",
    "    En cada iteración, se escribe una fila en el archivo CSV con los valores de 'provincia' y 'localidad' correspondientes.\"\"\"\n",
    "    with open('data/localities_new.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['provincia', 'localidad']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        \n",
    "        for k in list(zip(provincias,localidades)):\n",
    "            \n",
    "            writer.writerow({'provincia': k[0], 'localidad': k[1]})\n",
    "\n",
    "    \"\"\"Finalmente, la función no devuelve ningún valor explícito, ya que solo se encarga de realizar la extracción\n",
    "    y guardado de los datos en el archivo CSV.\"\"\"\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las funciones de extracción realizan consultas por provincia, para un mejor analisis funcional. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que realiza consultas a la [web](https://codigo-postal.co/argentina/) para extraer la variable __cpa__ de cada localidad con menos de 500 habitantes. Con más de 500 habitantes devuelve el valor _Buscar CPA_. El código proporcionado en la función llamada extraer_localities(provincias) se encarga de extraer datos de localidades y códigos postales del sitio [web](https://codigo-postal.co/argentina/) y guardarlos en un nuevo archivo CSV específico para cada provincia. A continuación, se comentan las líneas de código para comprender su significado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_localities(provincias):\n",
    "    \n",
    "    \"\"\"Aquí se abre un archivo CSV llamado \"localities_new.csv\", generado por la funcion anterior, en modo de lectura. Se lee el contenido del archivo utilizando csv.reader\n",
    "    y se guarda en la variable csv_readers. Luego, se itera sobre los elementos de csv_readers\n",
    "    y se verifica si la primera columna coincide con la provincia proporcionada (provincias). Si hay una coincidencia, se agrega el elemento a la lista csv_reader.\"\"\"\n",
    "    with open(\"data/localities_new.csv\", 'r') as file:\n",
    "        csv_readers = csv.reader(file)\n",
    "        csv_reader = []\n",
    "        for i in list(csv_readers):\n",
    "            if i[0] == provincias:\n",
    "                csv_reader.append(i)\n",
    "\n",
    "        \"\"\"Aquí se crea una sesión de solicitud HTTP utilizando requests.Session(). Luego, se realiza una solicitud GET a una URL específica para la provincia proporcionada.\n",
    "        Después, se itera sobre los elementos de csv_reader. Para cada elemento, se inicializan las listas provincia, localidades\n",
    "        y CPA_localidad. Se forma una cadena localidad concatenando la provincia y la localidad actual del elemento de csv_reader en un formato adecuado para la URL.\"\"\"\n",
    "        session = requests.Session()\n",
    "        cpa_csv = []\n",
    "        response1 = session.get(f'https://codigo-postal.co/argentina/{provincias}')\n",
    "        for row in list(csv_reader):\n",
    "            provincia = []\n",
    "            localidades = []\n",
    "            CPA_localidad = []\n",
    "            localidad = f\"{provincias}/{row[1]}\".lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "            \n",
    "            \"\"\"Aquí se intenta construir la URL para la solicitud HTTP.\n",
    "            Se verifica si la localidad no está en la columna 1 de cpa_csv\n",
    "            y se construye la URL. En cualquier caso, se asegura de que la variable url tenga el valor correcto para la solicitud.\"\"\"\n",
    "            try:\n",
    "                if row[1] not in list(zip(*cpa_csv))[1]:\n",
    "                    url = f\"https://codigo-postal.co/argentina/{localidad}\"\n",
    "                else:\n",
    "                    continue\n",
    "            except:\n",
    "                url = f\"https://codigo-postal.co/argentina/{localidad}\"\n",
    "            \n",
    "            \"\"\"Aquí se realiza una solicitud GET a la URL construida anteriormente utilizando la sesión HTTP. Si la respuesta tiene un código de estado 200 (éxito),\n",
    "            se obtiene el contenido de la respuesta y se analiza utilizando BeautifulSoup para poder extraer datos de él.\n",
    "            Si ocurre alguna excepción al realizar la solicitud o al analizar el contenido, se pasa a la siguiente iteración del bucle.\"\"\"\n",
    "            try:\n",
    "                response2 = session.get(url)\n",
    "                if response2.status_code == 200:\n",
    "                    content = response2.content\n",
    "                    soup = BeautifulSoup(content, \"html.parser\")\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            \"\"\"Aquí se intenta encontrar una tabla en el contenido analizado. Si se encuentra, se itera sobre las filas de la tabla\n",
    "            y se extraen los valores de las columnas correspondientes a la provincia, localidad y CPA. Estos valores se agregan a las listas provincia,\n",
    "            localidades y CPA_localidad. Si no se puede encontrar la tabla o extraer los valores, se agrega el valor de la provincia\n",
    "            y la localidad del elemento actual de csv_reader a las listas correspondientes y se establece el valor \"Buscar CPA\" para el CPA.\"\"\"\n",
    "            try:\n",
    "                table = soup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "                # Extraer la variable \"provincia\".\n",
    "                provincia.extend([i.find_all(\"td\")[0].get_text() for i in table])\n",
    "                # Extraer la variable localidad.\n",
    "                localidades.extend([i.find_all(\"td\")[1].get_text() for i in table])\n",
    "                # Extraer la variable CPA.\n",
    "                CPA_localidad.extend([i.find_all(\"td\")[3].get_text() for i in table])\n",
    "            except:\n",
    "                provincia.append(row[0])\n",
    "                localidades.append(row[1])\n",
    "                CPA_localidad.append(\"Buscar CPA\")\n",
    "            \n",
    "            \"\"\"Aquí se crea una lista de tuplas combinando los valores de provincia, localidades\n",
    "            y CPA_localidad. Luego, se convierte la lista en un conjunto para eliminar duplicados\n",
    "            y finalmente se convierte nuevamente en una lista.\"\"\"\n",
    "            for i in list(zip(provincia,localidades,CPA_localidad)):\n",
    "                cpa_csv.append(i)\n",
    "            cpa_csv = list(set(cpa_csv))\n",
    "    \n",
    "    \"\"\"Aquí se abre un nuevo archivo CSV con un nombre específico basado en la provincia proporcionada.\n",
    "    Se especifican los nombres de campo para el encabezado del archivo CSV.\n",
    "    Luego, se utiliza csv.DictWriter para escribir las filas en el archivo CSV utilizando los valores de las tuplas en cpa_csv.\"\"\"\n",
    "    with open(f'data/localities_{provincias}.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['localidad', 'cpa_localidad','provincia']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        for k in cpa_csv:\n",
    "            writer.writerow({'localidad': k[1], 'cpa_localidad': k[2],'provincia': k[0]})\n",
    "\n",
    "    \"\"\"En resumen, la función extraer_localities(provincias) lee el archivo \"localities_new.csv\" para obtener una lista de localidades\n",
    "    y luego realiza solicitudes HTTP para obtener los códigos postales de esas localidades desde un sitio web. Luego, guarda los datos\n",
    "    obtenidos en un nuevo archivo CSV específico para la provincia proporcionada.\"\"\"\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que realiza consultas a la [web](https://codigo-postal.co/argentina/) para extraer la variable __calles/avenidas/rutas__. El código proporcionado en la función llamada extraer_streets(pro) se encarga de extraer datos de calles asociadas a localidades en una provincia específica desde un sitio web y guardarlos en un nuevo archivo CSV. A continuación, se comentan las líneas de código para comprender su significado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_streets(pro):\n",
    "\n",
    "    \"\"\"Aquí se abre un archivo CSV específico, creado anteriormente, para la provincia proporcionada, llamado \"localities_{pro}.csv\", en modo de lectura.\n",
    "    Se lee el contenido del archivo utilizando csv.reader y se itera sobre los elementos.\n",
    "    Si la segunda columna del elemento es igual a \"Buscar CPA\", se agrega el valor de la primera columna (localidad) a la lista localidades.\"\"\"\n",
    "    localidades = []\n",
    "    with open(f\"data/localities_{pro}.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "            if i[1] == \"Buscar CPA\":\n",
    "                localidades.append(i[0])\n",
    "\n",
    "    \"\"\"Aquí se crea una sesión de solicitud HTTP utilizando requests.Session(). Luego, se realiza una solicitud GET a una URL específica para la provincia proporcionada\n",
    "    y se guarda la respuesta en response1. Se inicializan las listas street y localidad para almacenar los datos de las calles y las localidades, respectivamente.\"\"\"\n",
    "    session = requests.Session()\n",
    "    response1 = session.get(f'https://codigo-postal.co/argentina/{pro}')\n",
    "    street = []\n",
    "    localidad = []\n",
    "\n",
    "    \"\"\"Aquí se itera sobre cada localidad en la lista localidades. Se construye una cadena loc a partir de la localidad actual,\n",
    "    en un formato adecuado para la URL. Luego, se realiza una solicitud GET a una URL específica para la provincia y localidad actual,\n",
    "    y se guarda la respuesta en response2. Si la respuesta tiene un código de estado 200 (éxito), se obtiene el contenido de la respuesta\n",
    "    y se analiza utilizando BeautifulSoup para poder extraer datos de él. Se encuentra la lista de elementos HTML que contienen las calles\n",
    "    y se extraen los nombres de las calles. Estos nombres se agregan a la lista street, y se crea una lista localidads con la localidad actual repetida para cada calle.\n",
    "    Luego, se agregan las calles y las localidades a las listas street y localidad, respectivamente.\"\"\"\n",
    "    for p in localidades:\n",
    "        loc = p.lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "        response2 = session.get(f'https://codigo-postal.co/argentina/{pro}/calles-de-{loc}')\n",
    "        if response2.status_code == 200:\n",
    "            content = response2.content\n",
    "            soup = BeautifulSoup(content, \"html.parser\")\n",
    "        lista = soup.find(class_=\"three_columns\").find_all(\"li\")\n",
    "        streets = [i.find(\"a\").get_text() for i in lista]\n",
    "        street.extend(streets)\n",
    "        localidads = [p] * len(streets)\n",
    "        localidad.extend(localidads)\n",
    "    \n",
    "    \"\"\"Aquí se abre un nuevo archivo CSV con un nombre específico basado en la provincia proporcionada,\n",
    "    llamado \"streets_{pro}.csv\", en modo de escritura. Se especifican los nombres de campo para el encabezado del archivo CSV.\n",
    "    Luego, se utiliza csv.DictWriter para escribir las filas en el archivo CSV utilizando los valores de las listas localidad\n",
    "    y street en combinación. Cada fila representa una localidad y una calle asociada.\"\"\"\n",
    "    with open(f'data/streets_{pro}.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['localidad','street']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        for k in list(zip(localidad,street)):\n",
    "            writer.writerow({'localidad': k[0],'street':k[1]})\n",
    "\n",
    "    \"\"\"En resumen, la función extraer_streets(pro) lee un archivo CSV que contiene localidades asociadas a una provincia específica.\n",
    "    Luego, realiza solicitudes HTTP para obtener las calles asociadas\n",
    "    a cada localidad desde un sitio web y guarda los datos en un nuevo archivo CSV específico para la provincia proporcionada.\"\"\"\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función que realiza consultas a la [web](https://codigo-postal.co/argentina/) para extraer las variables __isOdd__, __from__, __until__ y __zip__ de cada calle/avenida/ruta. El código proporcionado en la función llamada extraer_numbers(pro) que se encarga de extraer datos de cpa de calles en una provincia específica desde un sitio [web](https://codigo-postal.co/argentina/) y guardarlos en un nuevo archivo CSV. A continuación, se comentan las líneas de código para comprender su significado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_numbers(pro):\n",
    "\n",
    "    \"\"\"Aquí se abre un archivo CSV específico para la provincia proporcionada, llamado \"streets_{pro}.csv\",\n",
    "    en modo de lectura. Se lee el contenido del archivo utilizando csv.reader y se itera sobre los elementos.\n",
    "    Se agrega el valor de la primera columna (localidad) a la lista localidad,\n",
    "    y se agrega el valor de la segunda columna (calle) a la lista calles.\"\"\"\n",
    "    calles = []\n",
    "    localidad = []\n",
    "    with open(f\"data/streets_{pro}.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "            localidad.append(i[0])\n",
    "            calles.append(i[1])\n",
    "\n",
    "    \"\"\"Aquí se crea una sesión de solicitud HTTP utilizando requests.Session(). Luego, se realiza una solicitud GET a una URL específica\n",
    "    para la provincia proporcionada y se guarda la respuesta en response0.\n",
    "    Se inicializan las listas street, isOdd, froms, until, zips y localidads para almacenar los datos de las calles.\"\"\"\n",
    "    session = requests.Session()\n",
    "    response0 = session.get(f'https://codigo-postal.co/argentina/{pro}')\n",
    "    street = []\n",
    "    isOdd = []\n",
    "    froms = []\n",
    "    until = []\n",
    "    zips = []\n",
    "    localidads = []\n",
    "\n",
    "    \"\"\"A continuación, se itera sobre cada localidad en la lista localidad. Se formatea el nombre de la localidad\n",
    "    para que coincida con la URL del sitio web. Luego, se realiza una solicitud GET a una URL específica para la provincia\n",
    "    y la localidad. Si la respuesta es exitosa (código de estado 200),\n",
    "    se extraen los datos de la tabla HTML que contiene la información de las calles.\"\"\"\n",
    "    for lo in localidad:\n",
    "        loc = lo.lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "        response1 = session.get(f'https://codigo-postal.co/argentina/{pro}/{loc}')\n",
    "        for c in calles:\n",
    "\n",
    "            \"\"\"Dentro del bucle for c in calles, se procesa cada calle de la lista calles. Se realiza una serie de transformaciones\n",
    "            en el nombre de la calle para que coincida con la URL del sitio web. Luego, se realiza una solicitud GET a una URL específica\n",
    "            para la provincia, la localidad y la calle. Si la respuesta es exitosa,\n",
    "            se procesa el contenido HTML para extraer los datos de la tabla y se almacenan en las listas correspondientes.\"\"\"\n",
    "            if c.replace(\"Calle \",\"\") not in [str(i) for i in range(100)]:\n",
    "                ca = c.replace(\"/\",\"\").replace(\"Calle \",\"\").replace(\"Boulevard \",\"\").replace(\"Avenida \",\"\").replace(\"Ruta Provincial \",\"\").replace(\"Pasaje \",\"\").lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "            else:\n",
    "                ca = c.replace(\"/\",\"\").replace(\"Boulevard \",\"\").replace(\"Avenida \",\"\").replace(\"Ruta Provincial \",\"\").replace(\"Pasaje \",\"\").lower().replace(\" \",\"-\").replace(\"ñ\",\"n\")\n",
    "            \n",
    "            \n",
    "            response2 = session.get(f'https://codigo-postal.co/argentina/{pro}/{loc}/{ca}')\n",
    "            if response2.status_code == 200:\n",
    "                content = response2.content\n",
    "                soup = BeautifulSoup(content, \"html.parser\")\n",
    "            \n",
    "        \n",
    "            calle = []\n",
    "            desde = []\n",
    "            hasta = []\n",
    "            aplica_a = []\n",
    "            cpa = []\n",
    "            \n",
    "            try:\n",
    "                lista = soup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "            except:\n",
    "                continue\n",
    "            for row in lista:\n",
    "                row = row.find_all(\"td\")\n",
    "                calle.append(row[0].get_text())\n",
    "                desde.append(row[1].get_text())\n",
    "                hasta.append(row[2].get_text())\n",
    "                aplica_a.append(row[3].get_text())\n",
    "                cpa.append(row[5].get_text())\n",
    "            \n",
    "            street.extend(calle)\n",
    "            froms.extend(desde)\n",
    "            until.extend(hasta)\n",
    "            isOdd.extend(aplica_a)\n",
    "            zips.extend(cpa)\n",
    "            localidadss = [lo] * len(calle)\n",
    "            localidads.extend(localidadss)\n",
    "            \n",
    "    \"\"\"Finalmente, se abre un nuevo archivo CSV llamado \"numbers_{pro}.csv\" en modo de escritura. Se especifican los nombres\n",
    "    de campo para el encabezado del archivo CSV. Se utiliza csv.DictWriter para escribir las filas en el archivo CSV utilizando los valores de las listas street,\n",
    "    froms, until, isOdd, zips y localidads en combinación. Cada fila representa un cpa de calle con información asociada.\"\"\"\n",
    "    with open(f'data/numbers_{pro}.csv', 'w', newline='') as file:\n",
    "        fieldnames = ['street','froms','until','isOdd','zips','localidads']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        \n",
    "        for k in list(zip(street,froms,until,isOdd,zips,localidads)):\n",
    "            \n",
    "            writer.writerow({'street':k[0],'froms':k[1],'until':k[2],'isOdd':k[3],'zips':k[4],'localidads':k[5]})\n",
    "\n",
    "    return"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones de limpieza."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza y transformacion de __localities_tucuman.csv__ del ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localities_transformacion(pro):\n",
    "\n",
    "    datos = []\n",
    "    with open(f\"data/localities_{pro}.csv\", 'r',encoding=\"latin-1\") as archivo:\n",
    "        reader = csv.reader(archivo)\n",
    "        datos = list(reader)\n",
    "\n",
    "    # Definir los encabezados\n",
    "    encabezados = [\"name\",\"zip\",\"sate\"]\n",
    "\n",
    "    # Escribir los datos junto con los encabezados en un nuevo archivo CSV\n",
    "    with open(f\"localities_{pro}.csv\", 'w', newline='') as archivo:\n",
    "        writer = csv.writer(archivo)\n",
    "        writer.writerow(encabezados)  # Escribir los encabezados en la primera fila\n",
    "\n",
    "        for fila in datos:\n",
    "            writer.writerow(fila)  # Escribir cada fila de datos\n",
    "\n",
    "    datos = []\n",
    "    with open(f\"localities_{pro}.csv\", 'r') as archivo:\n",
    "        reader = csv.DictReader(archivo)\n",
    "        for fila in reader:\n",
    "            datos.append(fila)\n",
    "\n",
    "    # Agregar la columna de ID a cada diccionario en la lista\n",
    "    for i, fila in enumerate(datos):\n",
    "        fila['id'] = \"{:07d}\".format(i+1)\n",
    "\n",
    "    # Escribir los datos actualizados en un nuevo archivo CSV que incluya la columna de id\n",
    "    encabezados = ['id'] + reader.fieldnames  # Agregar 'id' al inicio de los encabezados\n",
    "\n",
    "    with open(f\"data/localities_{pro}_final.csv\", 'w', newline='') as archivo:\n",
    "        writer = csv.DictWriter(archivo, fieldnames=encabezados)\n",
    "        writer.writeheader()  # Escribir los encabezados en la primera fila\n",
    "\n",
    "        for fila in datos:\n",
    "            writer.writerow(fila)  # Escribir cada fila con los datos actualizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "localities_transformacion(\"tucuman\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza y transformacion de __streets_tucuman.csv__ del ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streets_transformacion(pro):\n",
    "\n",
    "    localidad = []\n",
    "    id = []\n",
    "    with open(f\"data/localities_{pro}_final.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "            if i[2] == \"Buscar CPA\":\n",
    "                id.append(i[0])\n",
    "                localidad.append(i[1])\n",
    "\n",
    "    localities = dict(zip(localidad,id))\n",
    "\n",
    "    loc_streets = []\n",
    "    calle_streets = []\n",
    "    with open(f\"data/streets_{pro}.csv\", 'r',encoding=\"latin-1\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "                calle_streets.append(i[1])\n",
    "                loc_streets.append(i[0])\n",
    "\n",
    "    loc_streets_new = []\n",
    "    for i in loc_streets:\n",
    "        i = localities[i]\n",
    "        loc_streets_new.append(i)\n",
    "\n",
    "    types = []\n",
    "    for i in calle_streets:\n",
    "        for keyword in [\"Calle\", \"Boulevard\", \"Avenida\", \"Ruta Provincial\", \"Pasaje\"]:\n",
    "            if keyword in i:    \n",
    "                types.append(keyword)\n",
    "                break\n",
    "\n",
    "    with open(f'streets_{pro}_final.csv', 'w', newline='') as file:\n",
    "        fieldnames = [\"type\",\"name\",\"localityId\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for k in list(zip(types,calle_streets,loc_streets_new)):\n",
    "            \n",
    "            writer.writerow({'type':k[0],'name':k[1],'localityId':k[2]})\n",
    "\n",
    "    datos = []\n",
    "    with open(f\"streets_{pro}_final.csv\", 'r') as archivo:\n",
    "            reader = csv.DictReader(archivo)\n",
    "            for fila in reader:\n",
    "                datos.append(fila)\n",
    "\n",
    "    # Agregar la columna de ID a cada diccionario en la lista\n",
    "    for i, fila in enumerate(datos):\n",
    "        fila['id'] = \"{:07d}\".format(i+1)\n",
    "\n",
    "    # Escribir los datos actualizados en un nuevo archivo CSV que incluya la columna de id\n",
    "    encabezados = ['id'] + reader.fieldnames  # Agregar 'id' al inicio de los encabezados\n",
    "\n",
    "    with open(f\"data/streets_{pro}_final.csv\", 'w', newline='') as archivo:\n",
    "        writer = csv.DictWriter(archivo, fieldnames=encabezados)\n",
    "        writer.writeheader()  # Escribir los encabezados en la primera fila\n",
    "\n",
    "        for fila in datos:\n",
    "            writer.writerow(fila)  # Escribir cada fila con los datos actualizados\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "streets_transformacion(\"tucuman\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza y transformacion de __numbers_tucuman.csv__ del ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers_transformacion(pro):\n",
    "\n",
    "    par_impar = []\n",
    "    calle = []\n",
    "    froms = []\n",
    "    untils = []\n",
    "    zips = []\n",
    "    with open(f\"data/numbers_tucuman.csv\", 'r',encoding=\"latin-1\") as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "            \n",
    "                par_impar.append(i[3])\n",
    "                calle.append(i[0])\n",
    "                froms.append(i[1])\n",
    "                untils.append(i[2])\n",
    "                zips.append(i[4])\n",
    "\n",
    "    pa_im = {\"números impares\":\"true\",\"números pares\":\"false\"}\n",
    "    is0dd = []\n",
    "    for i in par_impar:\n",
    "        i = pa_im[i]\n",
    "        is0dd.append(i)\n",
    "\n",
    "    calless = []\n",
    "    ids = []\n",
    "    with open(f\"data/streets_tucuman_final.csv\", 'r') as file:\n",
    "        csv_reader = csv.reader(file)\n",
    "        for i in csv_reader:\n",
    "            \n",
    "                ids.append(i[0])\n",
    "                calless.append(i[2])\n",
    "\n",
    "    calles = dict(zip(calless,ids))\n",
    "    \n",
    "    streetId = []\n",
    "    for i in calle:\n",
    "            try:\n",
    "                i = calles[i]\n",
    "                streetId.append(i)\n",
    "            except:\n",
    "                 continue\n",
    "\n",
    "    with open(f'data/numbers_tucuman_final.csv', 'w', newline='') as file:\n",
    "        fieldnames = [\"streetId\",\"is0dd\",\"from\",\"until\",\"zip\"]\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for k in list(zip(streetId,is0dd,froms,untils,zips)):\n",
    "            \n",
    "            writer.writerow({'streetId':k[0],'is0dd':k[1],'from':k[2],'until':k[3],'zip':k[4]})\n",
    "    \n",
    "    \n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_transformacion(\"tucuman\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CPA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
