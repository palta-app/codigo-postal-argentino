{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a40481-10fd-458c-9359-00e7d59384fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T15:37:04.232976Z",
     "iopub.status.busy": "2023-06-07T15:37:04.232459Z",
     "iopub.status.idle": "2023-06-07T15:37:05.448468Z",
     "shell.execute_reply": "2023-06-07T15:37:05.446998Z",
     "shell.execute_reply.started": "2023-06-07T15:37:04.232930Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416b7466-b797-45ab-b0d9-09608b39ebc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T15:37:05.483986Z",
     "iopub.status.busy": "2023-06-07T15:37:05.483269Z",
     "iopub.status.idle": "2023-06-07T15:37:05.519032Z",
     "shell.execute_reply": "2023-06-07T15:37:05.517634Z",
     "shell.execute_reply.started": "2023-06-07T15:37:05.483925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Lee el archivo CSV\n",
    "df_provinces = pd.read_csv('../data/lista_provincias.csv')\n",
    "\n",
    "# Provincias sin Buenos Aires, Capital y Córdoba\n",
    "# Eliminar las filas correspondientes a las provincias especificadas\n",
    "provincias_a_eliminar = [\"buenos-aires\", \"buenos-aires-(caba)\", \"cordoba\"]\n",
    "df_provinces = df_provinces[~df_provinces[\"Provincia\"].isin(provincias_a_eliminar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2c8a3-74a6-4491-8343-71cf5890cc42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-07T15:37:06.559536Z",
     "iopub.status.busy": "2023-06-07T15:37:06.558894Z"
    }
   },
   "outputs": [],
   "source": [
    "base_url = \"https://codigo-postal.co/argentina/\"\n",
    "\n",
    "# Para cada provincia en el DataFrame\n",
    "for index, row in df_provinces.iterrows():\n",
    "    # Carga el archivo CSV de localidades para la provincia actual\n",
    "    df_localities = pd.read_csv(f'../data/provincias/{row[\"Provincia\"]}_localidad.csv')\n",
    "\n",
    "    # Crea una lista vacía para almacenar los datos extraídos\n",
    "    data = []\n",
    "\n",
    "    # Para cada localidad en el DataFrame\n",
    "    for i, r in df_localities.iterrows():\n",
    "        # Crea la URL para la localidad\n",
    "        locality_url = base_url + row['Provincia'] + '/' + r['Localidad']\n",
    "       # Para cada provincia en el DataFrame\n",
    "for index, row in df_provinces.iterrows():\n",
    "    provincia = row[\"Provincia\"]\n",
    "    \n",
    "    # Evita que se ejecute el código para las provincias especificadas\n",
    "    if provincia not in [\"buenos-aires\", \"buenos-aires(caba)\", \"cordoba\"]:\n",
    "        # Carga el archivo CSV de localidades para la provincia actual\n",
    "        df_localities = pd.read_csv(f'../data/provincias/{provincia}_localidad.csv')\n",
    "\n",
    "        # Crea una lista vacía para almacenar los datos extraídos\n",
    "        data = []\n",
    "\n",
    "        # Para cada localidad en el DataFrame\n",
    "        for i, r in df_localities.iterrows():\n",
    "            # Crea la URL para la localidad\n",
    "            locality_url = base_url + provincia + '/' + r['Localidad']\n",
    "           \n",
    "            # Solicita la página\n",
    "            response = requests.get(locality_url)\n",
    "            \n",
    "            # Analiza el HTML de la página\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Encuentra el CPA en la página\n",
    "            cpa_link = soup.find('tbody').find('a') if soup.find('tbody') else None\n",
    "            if cpa_link:\n",
    "                cpa = cpa_link.text.strip()\n",
    "                \n",
    "                # Añade la localidad y el CPA a la lista\n",
    "                data.append({\"Localidad\": r['Localidad'], \"CPA\": cpa})\n",
    "\n",
    "            # Pausa para evitar sobrecargar el servidor\n",
    "            time.sleep(.5)\n",
    "        \n",
    "        # Convierte la lista en un DataFrame\n",
    "        df_cpa = pd.DataFrame(data)\n",
    "        \n",
    "        # Guarda el DataFrame en un archivo CSV\n",
    "        df_cpa.to_csv(f'{provincia}_cpa.csv', index=False)\n",
    "\n",
    "        # Solicita la página\n",
    "        response = requests.get(locality_url)\n",
    "        \n",
    "        # Analiza el HTML de la página\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Encuentra el CPA en la página\n",
    "        cpa_link = soup.find('tbody').find('a') if soup.find('tbody') else None\n",
    "        if cpa_link:\n",
    "            cpa = cpa_link.text.strip()\n",
    "            \n",
    "            # Añade la localidad y el CPA a la lista\n",
    "            data.append({\"Localidad\": r['Localidad'], \"CPA\": cpa})\n",
    "\n",
    "        # Pausa para evitar sobrecargar el servidor\n",
    "        time.sleep(.5)\n",
    "    \n",
    "    # Convierte la lista en un DataFrame\n",
    "    df_cpa = pd.DataFrame(data)\n",
    "    \n",
    "    # Guarda el DataFrame en un archivo CSV\n",
    "    df_cpa.to_csv(f'../target/provinces/{row[\"Provincia\"]}_cpa.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
